<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>StyleMorph</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Prevent search engines from indexing page
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="robots" content="noindex">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/skeleton.css">
  <link rel="stylesheet" href="css/skeleton.css">
  <link rel="stylesheet" type="text/css" href="css/video-comparison.css">

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.js"></script>
  <script type="text/javascript" src="synchronize.js"></script>
  <script type="text/javascript" src="video-comparison.js"></script>
  
</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">
      <div class="has-text-centered" style="margin-top: 5%">
        <h1 class="section-heading">StyleMorph</h1>
        <p>Disentangling Shape, Pose and Appearance through 3D Morphable Image and Geometry Generation</p>
      </div>
    </div>
    <div class="container">
      <div class="row">
        <div class="has-text-centered" style="margin-top: 0% margin-bottom: 20%">
          <video width="100%" controls muted autoplay loop>
            <source src="videos/overview_anonymous.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    <div class="row">
      <div class="has-text-centered" style="margin-top: 3%">
        <h4>Anonymous</h4>
        
      </div>
    </div>
    
    <div class="row">
      <div class="one-half column has-text-centered" style="margin-left: 0%; width: 50%">        
        <figure style="margin-bottom: 0%">
          <a href="https://arxiv.org/"><img src="images/arxiv_logo.png" width="64" width="64"/></a>
        </figure>
        <a href="https://arxiv.org/">Paper and Supplemental - Coming Soon!</a>
      </div>
      <div class="one-half column has-text-centered" style="margin-left: 0%; width: 50%">
        <figure style="margin-bottom: 0%">
          <a href="https://github.com/stylemorph/stylemorph"><img src="images/github_logo.png" width="64" width="64"/></a>
        </figure>
        <a href="">Code - Coming Soon!</a>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="has-text-centered" style="margin-top: 8%">
        <h3 class="section-heading">Abstract</h3>
        <p>We introduce StyleMorph, a 3D-aware generative model that disentangles 3D shape, camera pose, object appearance, and background appearance for high quality image synthesis. We account for shape variability by morphing a canonical 3D object template, effectively learning a 3D morphable model in an entirely unsupervised manner through backprop. We chain 3D morphable modelling with deferred neural rendering by performing an implicit surface rendering of “Template Object Coordinates” (TOCS), which can be understood as an unsupervised counterpart to UV maps. This provides a detailed 2D TOCS map signal that reflects the compounded geometric effects of non-rigid shape variation, camera pose, and perspective projection. We combine 2D TOCS maps with an independent appearance code to condition a StyleGAN-based deferred neural rendering (DNR) network for foreground image (object) synthesis; we use a separate code for background synthesis and do late fusion to deliver the final result. We show competitive synthesis results on 4 datasets (FFHQ faces, AFHQ Cats, Dogs, Wild), while achieving the joint disentanglement of shape, pose, object and background texture.</p>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="has-text-centered" style="margin-top: 8%">
        <h3 class="section-heading">Method</h3>
        <img src="images/pipeline.png" width="100%"/>
        <p>Our method trains on an unstructured collection of RGB images. We learn a generative model that <b>(i)</b> disentangles camera, shape and foreground/background appearance, <b>(ii)</b> expresses shape variability through deformations and <b>(iii)</b> efficiently generates high resolution, realistic images.</p>
        <p>We model canonical shape as a signed distance function in template space, and warp it using a non-rigid shape deformation <img src="images/z_s.png" width=19>. We render template coordinates using camera pose (<b>φ</b>, <b>θ</b>),
          and perspective projection, to produce a rendered 2D Template Object Coordinate System (TOCS). The 2D TOCS maps are passed into a Deferred Neural Rendering network together with latent codes for foreground
          and background appearance (<img src="images/z_fg.png" width=24>, <img src="images/z_bg.png" width=24>) to produce high-resolution photorrealistic images trained by a discriminator network.</p>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="has-text-centered" style="margin-top: 8%">
        <h3 class="section-heading">TOCS representation</h3>
        <p>We warp camera rays from world to template space and use differentiable rendering to produce “Template Object Coordinates” (TOCS). TOCS maps provide dense image-to-template object correspondences. They reflect the compounded effects of non-rigid shape, pose, and perspective projection, but are appearance-agnostic. They feed into a Deferred Neural Renderer together with latent codes for foreground and background appearance to produce photorrealistic images.</p>
        <p>Drag the slider to reveal the TOCS maps underlying our image synthesis</p>
      </div>
    </div>
    <div class="row">
      <div class="one-half column">
      <div class="vcs_wrapper" data-loop="true">
          <video muted autoplay loop>
              <source src="videos/sliders/slider1_bottom.mp4" type="video/mp4">
        </video>
        <video muted autoplay loop>
              <source src="videos/sliders/slider1_top.mp4" type="video/mp4">
        </video>
      </div>
      </div>
      <div class="one-half column">
        <div class="vcs_wrapper" data-loop="true">
            <video muted autoplay loop>
            <source src="videos/sliders/slider2_bottom.mp4" type="video/mp4">
          </video>
          <video muted autoplay loop>
                <source src="videos/sliders/slider2_top.mp4" type="video/mp4">
          </video>
        </div>
        </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="has-text-centered" style="margin-top: 8%">
        <h3 class="section-heading">Results</h3>
        <p>Our approach uses separate latent codes for shape, background and foreground appearance. By varying codes in one latent space and holding the others fixed, our model exhibits disentangled synthesis with independent control over each factor of variation,
          in addition to 3D-consistent camera pose control.</p>
        <p>Below we show interpolation results from varying each factor of control on FFHQ and AFHQ datasets.</p>
      </div>
    </div>
    <div class="row has-text-centered" style="margin-top: 3%">
    <h5 class="section-heading" style="margin-bottom: 0%">FFHQ</h5>
  </div>
    <div class="row">
      
      <div class="one-third column has-text-centered">
        <figure>
          <video width="100%" muted autoplay loop>
            <source src="videos/interpolations/ffhq/fg.mp4" type="video/mp4">
          </video>                  
          <figcaption>Foreground</figcaption>
            </figure>
        </div>
        <div class="one-third column has-text-centered">
          <figure>
            <video width="100%" muted autoplay loop>
              <source src="videos/interpolations/ffhq/bg.mp4" type="video/mp4">
            </video>                  
            <figcaption>Background</figcaption>
              </figure>
          </div>
          <div class="one-third column has-text-centered">
            <figure>
              <video width="100%" muted autoplay loop>
                <source src="videos/interpolations/ffhq/shape.mp4" type="video/mp4">
              </video>                  
              <figcaption>Shape</figcaption>
                </figure>
            </div>
    </div>
    <div class="row">
      <div class="one-half column" style="text-align:right">
        <figure>
          <video width="100%" muted autoplay loop>
            <source src="videos/interpolations/ffhq/azi.mp4" type="video/mp4">
          </video>                  
          <figcaption class="has-text-centered">Pose 1</figcaption>
            </figure>
        </div>
        <div class="one-half column" style="text-align:left">
          <figure>
            <video width="100%" muted autoplay loop>
              <source src="videos/interpolations/ffhq/ellipsoid.mp4" type="video/mp4">
            </video>                  
            <figcaption class="has-text-centered">Pose 2</figcaption>
              </figure>
          </div>
    </div>
    <div class="row has-text-centered" style="margin-top: 3%">
      <h5 class="section-heading" style="margin-bottom: 0%">AFHQ Cats</h5>
    </div>
      <div class="row">
        
        <div class="one-third column has-text-centered">
          <figure>
            <video width="100%" muted autoplay loop>
              <source src="videos/interpolations/cats/fg.mp4" type="video/mp4">
            </video>                  
            <figcaption>Foreground</figcaption>
              </figure>
          </div>
          <div class="one-third column has-text-centered">
            <figure>
              <video width="100%" muted autoplay loop>
                <source src="videos/interpolations/cats/bg.mp4" type="video/mp4">
              </video>                  
              <figcaption>Background</figcaption>
                </figure>
            </div>
            <div class="one-third column has-text-centered">
              <figure>
                <video width="100%" muted autoplay loop>
                  <source src="videos/interpolations/cats/shape.mp4" type="video/mp4">
                </video>                  
                <figcaption>Shape</figcaption>
                  </figure>
              </div>
      </div>
      <div class="row">
        <div class="one-half column" style="text-align:right">
          <figure>
            <video width="100%" muted autoplay loop>
              <source src="videos/interpolations/cats/azi.mp4" type="video/mp4">
            </video>                  
            <figcaption class="has-text-centered">Pose 1</figcaption>
              </figure>
          </div>
          <div class="one-half column" style="text-align:left">
            <figure>
              <video width="100%" muted autoplay loop>
                <source src="videos/interpolations/cats/ellipsoid.mp4" type="video/mp4">
              </video>                  
              <figcaption class="has-text-centered">Pose 2</figcaption>
                </figure>
            </div>
      </div>
        <div class="row has-text-centered" style="margin-top: 3%">
          <h5 class="section-heading" style="margin-bottom: 0%">AFHQ Wild</h5>
        </div>
          <div class="row">
            
            <div class="one-third column has-text-centered">
              <figure>
                <video width="100%" muted autoplay loop>
                  <source src="videos/interpolations/wild/fg.mp4" type="video/mp4">
                </video>                  
                <figcaption>Foreground</figcaption>
                  </figure>
              </div>
              <div class="one-third column has-text-centered">
                <figure>
                  <video width="100%" muted autoplay loop>
                    <source src="videos/interpolations/wild/bg.mp4" type="video/mp4">
                  </video>                  
                  <figcaption>Background</figcaption>
                    </figure>
                </div>
                <div class="one-third column has-text-centered">
                  <figure>
                    <video width="100%" muted autoplay loop>
                      <source src="videos/interpolations/wild/shape.mp4" type="video/mp4">
                    </video>                  
                    <figcaption>Shape</figcaption>
                      </figure>
                  </div>
          </div>
          <div class="row">
            <div class="one-half column" style="text-align:right">
              <figure>
                <video width="100%" muted autoplay loop>
                  <source src="videos/interpolations/wild/azi.mp4" type="video/mp4">
                </video>                  
                <figcaption class="has-text-centered">Pose 1</figcaption>
                  </figure>
              </div>
              <div class="one-half column" style="text-align:left">
                <figure>
                  <video width="100%" muted autoplay loop>
                    <source src="videos/interpolations/wild/ellipsoid.mp4" type="video/mp4">
                  </video>                  
                  <figcaption class="has-text-centered">Pose 2</figcaption>
                    </figure>
                </div>
          </div>
  <div class="container">
    <div class="row">
      <div style="margin-top: 10%">
        <h3 class="section-heading has-text-centered">BibTeX</h3>
        <pre>
        <code>
            "@article{CitekeyArticle,
                author="TBC",
                title="TBC",
                journal="TBC",
                year=2022
              }"              
            </code>
            </pre>
      </div>
    </div>
    <!-- <div class="container">
      <h3 class="section-heading has-text-centered" style="margin-bottom:0">Acknowledgements</h3>
    <div class="row">
      
      <div class="one-third column" style="text-align:right">
        <figure class="verticalcenter">
          <a href="https://www.baskerville.ac.uk/"><img src="images/logos/Baskerville.png" width="100%"/></a>          
            </figure>
        </div>
        <div class="one-third column" style="text-align:center">
          <figure class="verticalcenter">
            <a href="https://www.turing.ac.uk/"><img src="images/logos/ati.png" width="100%"/></a>      
              </figure>
          </div>
        <div class="one-third column" style="text-align:left">
          <figure class="verticalcenter">
            <a href="https://www.jade.ac.uk/"><img src="images/logos/jade.png" width="100%"/></a>      
              </figure>
          </div>
    </div>
    <p style="text-align:center">All final models described in this research were
      trained using the <a href="https://www.baskerville.ac.uk/">Baskerville Tier 2 HPC service</a>. This was funded by EPSRC Grant EP/T022221/1
      and is operated by Advanced Research Computing at the University of Birmingham.
      This work was also supported in part by JADE: Joint Academic Data science
      Endeavour - 2 under the EPSRC Grant EP/T022205/1, & The Alan Turing Institute
      under EPSRC grant EP/N510129/1.
      We are grateful to Gabriel Browstow and Niloy Mitra
      for providing useful discussions and insights. </p>
  </div> -->
  </div>

<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>